# 神经网络

在机器学习中，神经网络一般指的是“神经网络学习”，是机器学习与神经网络两个学科的交叉部分。所谓神经网络，目前用得最广泛的一个定义是“神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所做出的交互反应”。

## 神经元模型

神经网络中最基本的单元是神经元模型（neuron）。在生物神经网络的原始机制中，每个神经元通常都有多个树突（dendrite），一个轴突（axon）和一个细胞体（cell body），树突短而多分支，轴突长而只有一个；在功能上，树突用于传入其它神经元传递的神经冲动，而轴突用于将神经冲动传出到其它神经元，当树突或细胞体传入的神经冲动使得神经元兴奋时，该神经元就会通过轴突向其它神经元传递兴奋。

受到生物神经网络的启发，利用激活函数实现了机器学习中的神经网络。

理想中的激活函数是阶跃函数，即只有0和1的输出，0对应神经元抑制，1对应神经元兴奋，不过阶跃函数不连续不光滑，所以使用Sigmoid函数来作为激活函数，既能实现阶跃函数的功能又是连续函数。

![img](https://syisbest.github.io/shenjingwangluo/1.png)

有了神经元模型和激活函数，那么将多个神经元按一定层次结构连接起来，就有了神经网络。

## 感知机与多层网络

感知机只有两层神经元，输入层和输出层

> 输出层是M-P神经元，“阀值逻辑单元”

利用感知机，可以很简单的实现与或非运算，![img](https://syisbest.github.io/shenjingwangluo/2.png)，这里f使用阶跃函数。

举例：

- “与”：令`w1=w2=1,θ=2`,则`y=f(x1+x2-2)`，当`x1=x2=1`时，`y=1`，`x1`和`x2`任意有一个为0,y就为0。
- “或”：令`w1=w2=1,θ=0.5`,则`y=f(x1+x2-0.5)`，当`x1=1或x2=1`时，`y=1`，`x1`和`x2`全为0时,y才为0。
- “非”：令`w1=-0.6,w2=0,θ=-0.5`,则`y=f(-0.6x1+0.5)`，当`x1=1`时，`y=0`，`x1=0`时，`y=1`。

很明显，感知机不能解决异或问题。

机器学习的标志：学习。所以给定训练集，权重和阀值就都可以通过学习得到，阀值又可以看作是一个固定的“哑节点”（-1.0），那么重点就在权重上，权重调整方法：

![img](https://syisbest.github.io/shenjingwangluo/3.png)

η取值（0,1），该参数称为学习率。

预测正确感知机就不会再发生变化了，否则就将错误的程度进行权重调整。

但是感知机因为他只有两层，没法解决非线性可分的问题，所以考虑使用多层神经元。

常见的神经网络每层神经元与下一层神经元完全互连，神经元之间不存在同层连接，也没有跨层连接。称之为“多层前馈神经网络”。

![img](https://syisbest.github.io/shenjingwangluo/4.png)

输入层神经元接收外界输入，隐层和输出层神经元对信号进行加工，最后由输出层神经元输出。

## 误差逆传播算法

大名鼎鼎的`BP`算法，在多层神经网络中使用的学习算法。

![img](https://syisbest.github.io/shenjingwangluo/5.png)

隐层和输出层神经元使用Sigmoid函数。

> 对于函数的推导表示不理解

算法的工作流程：

![img](https://syisbest.github.io/shenjingwangluo/6.png)

由这个流程可以一点点调整权和阀值，最后得到一个连接权与阀值确定的多层前馈神经网络。

由标准`BP`又能推导出累积`BP`，累积`BP`不需要很多次迭代，它只针对累积误差最小化，将整个训练集读取一遍后对参数进行一次更新，所以更新频率降低了。不过也会出现累积误差下降到了一定的程度后再想下降就变的很慢了，标准`BP`反而能更快的得到解。

![img](https://syisbest.github.io/shenjingwangluo/background.jpg)

*作者：沈岩，写于2020.6.7  10:35*

